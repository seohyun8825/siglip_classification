import argparse
import json
import os
from datetime import datetime
from typing import Optional, Tuple

from huggingface_hub import HfApi


def parse_args():
    p = argparse.ArgumentParser(description="Push trained model directories to the Hugging Face Hub with an autogenerated README.")
    p.add_argument("--output_dir", required=True, help="Training output directory (contains config.json or subdirs like best/, checkpoint-*/)")
    p.add_argument("--repo_namespace", required=True, help="Target HF namespace (user or org)")
    p.add_argument("--repo_main", default=None, help="Repo name for the main model (defaults to <basename> or <basename>-main if best is used)")
    p.add_argument("--repo_best", default=None, help="Repo name for the best model (defaults to <basename>-best if best exists)")
    p.add_argument("--private", action="store_true", help="Create repos as private")
    return p.parse_args()


def _find_model_dir(base: str) -> Optional[str]:
    base = os.path.abspath(os.path.expanduser(base))
    # If this dir has a config.json, accept
    if os.path.isdir(base) and os.path.exists(os.path.join(base, "config.json")):
        return base
    # Try best/ then last/
    for sub in ("best", "last"):
        p = os.path.join(base, sub)
        if os.path.isdir(p) and os.path.exists(os.path.join(p, "config.json")):
            return p
    # Try newest checkpoint-*
    ckpts = []
    if os.path.isdir(base):
        for name in os.listdir(base):
            if name.startswith("checkpoint-"):
                p = os.path.join(base, name)
                if os.path.isdir(p) and os.path.exists(os.path.join(p, "config.json")):
                    try:
                        step = int(name.split("-", 1)[1])
                    except Exception:
                        step = -1
                    ckpts.append((step, p))
    if ckpts:
        ckpts.sort(key=lambda x: x[0])
        return ckpts[-1][1]
    return None


def _compose_readme(output_dir: str, title_suffix: str = "") -> str:
    # Load optional artifacts
    sampling_path = os.path.join(output_dir, "train_sampling.json")
    best_metrics_path = os.path.join(output_dir, "best_metrics.json")
    train_eval_metrics_path = os.path.join(output_dir, "train_eval_metrics.json")

    sampling = None
    best_meta = None
    final_eval = None
    try:
        if os.path.exists(sampling_path):
            with open(sampling_path) as f:
                sampling = json.load(f)
    except Exception:
        sampling = None
    try:
        if os.path.exists(best_metrics_path):
            with open(best_metrics_path) as f:
                best_meta = json.load(f)
    except Exception:
        best_meta = None
    try:
        if os.path.exists(train_eval_metrics_path):
            with open(train_eval_metrics_path) as f:
                final_eval = json.load(f)
    except Exception:
        final_eval = None

    lines = []
    lines.append(f"# SigLIP Classification Model{(' - ' + title_suffix) if title_suffix else ''}")
    lines.append("")
    lines.append(f"Pushed: {datetime.utcnow().isoformat()}Z")
    lines.append("")

    # Metrics summary
    if best_meta or final_eval:
        lines.append("## Metrics")
        if best_meta:
            name = best_meta.get("best_metric_name", "accuracy")
            val = best_meta.get("best_metric_value", None)
            step = best_meta.get("best_step", None)
            lines.append(f"- Best ({name}): {val} @ step {step}")
        if final_eval:
            acc = final_eval.get("eval_accuracy", None)
            f1 = final_eval.get("eval_f1", None)
            lines.append(f"- Final eval: accuracy={acc}, f1={f1}")
        lines.append("")

    # Sampling summary
    if sampling:
        lines.append("## Train Sampling")
        mode = sampling.get("mode")
        lines.append(f"- mode: {mode}")
        if mode == "balanced":
            before = sampling.get("before", {})
            after = sampling.get("after", {})
            lines.append(f"- before: normal={before.get('normal')} abnormal={before.get('abnormal')} total={before.get('total')}")
            lines.append(f"- after: normal={after.get('normal')} abnormal={after.get('abnormal')} total={after.get('total')}")
        else:
            counts = sampling.get("counts", {})
            lines.append(f"- counts: normal={counts.get('normal')} abnormal={counts.get('abnormal')} total={counts.get('total')}")
        lines.append("")

    # Inference snippet
    lines.append("## Inference")
    lines.append("```")
    lines.append("from transformers import AutoImageProcessor, AutoModelForImageClassification")
    lines.append("from PIL import Image")
    lines.append("import torch")
    lines.append("processor = AutoImageProcessor.from_pretrained('<this-repo>')")
    lines.append("model = AutoModelForImageClassification.from_pretrained('<this-repo>')")
    lines.append("img = Image.open('your_image.png').convert('RGB')")
    lines.append("inputs = processor(images=img, return_tensors='pt')")
    lines.append("with torch.no_grad():")
    lines.append("    logits = model(**inputs).logits")
    lines.append("pred = logits.argmax(-1).item()")
    lines.append("print(model.config.id2label[pred])")
    lines.append("```")
    lines.append("")

    return "\n".join(lines)


def _push_dir(
    api: HfApi,
    local_dir: str,
    repo_id: str,
    private: bool,
    extra_files: Optional[Tuple[str, str]] = None,
    allow_patterns: Optional[list] = None,
    ignore_patterns: Optional[list] = None,
):
    api.create_repo(repo_id=repo_id, repo_type="model", private=private, exist_ok=True)
    # Upload model folder with filtering: keep only model/processor essentials by default
    api.upload_folder(
        repo_id=repo_id,
        repo_type="model",
        folder_path=local_dir,
        path_in_repo=".",
        allow_patterns=allow_patterns,
        ignore_patterns=ignore_patterns,
    )
    # Upload extra files (README, images)
    if extra_files:
        for src, dst in (extra_files if isinstance(extra_files, (list, tuple)) else [extra_files]):
            try:
                if os.path.exists(src):
                    api.upload_file(repo_id=repo_id, repo_type="model", path_or_fileobj=src, path_in_repo=dst)
            except Exception as e:
                print(f"[WARN] Failed to upload {src} to {repo_id}:{dst}: {e}")


def main():
    args = parse_args()
    api = HfApi()

    base = os.path.abspath(os.path.expanduser(args.output_dir))
    main_dir = _find_model_dir(base)
    if not main_dir:
        raise SystemExit(f"Could not find a model directory under: {base}")

    best_dir = None
    cand_best = os.path.join(base, "best")
    if os.path.isdir(cand_best) and os.path.exists(os.path.join(cand_best, "config.json")):
        best_dir = cand_best

    base_name = os.path.basename(base.rstrip("/")) or "model"
    repo_main = args.repo_main or base_name
    if best_dir and not args.repo_main:
        repo_main = f"{base_name}-main"
    repo_best = args.repo_best or (f"{base_name}-best" if best_dir else None)

    # Build READMEs
    readme_main = _compose_readme(base, title_suffix="main")
    readme_main_path = os.path.join(base, "MODEL_README_MAIN.md")
    with open(readme_main_path, "w") as f:
        f.write(readme_main)

    extra_files_main = [(readme_main_path, "README.md")]
    cm_png = os.path.join(base, "confusion_matrix.png")
    if os.path.exists(cm_png):
        extra_files_main.append((cm_png, "confusion_matrix.png"))

    repo_main_id = f"{args.repo_namespace}/{repo_main}"
    print(f"[push] Pushing main model: {main_dir} → {repo_main_id}")
    # Keep essentials only; drop training-only artifacts and nested checkpoints
    allow_main = [
        "config.json",
        "*.safetensors",
        "pytorch_model.bin",
        "pytorch_model.bin.index.json",
        "*processor_config.json",
        "preprocessor_config.json",
        "image_processor_config.json",
        "tokenizer*.json",
        "merges.txt",
        "vocab.*",
        "README.md",
        "confusion_matrix.png",
    ]
    ignore_main = [
        "checkpoint-*",
        "checkpoint-*/**",
        "best/**",
        "last/**",
        "**/*.pt",
        "**/events.*",
        "**/trainer_state.json",
        "**/training_args.bin",
    ]
    _push_dir(
        api,
        main_dir,
        repo_main_id,
        private=args.private,
        extra_files=extra_files_main,
        allow_patterns=allow_main,
        ignore_patterns=ignore_main,
    )

    if best_dir and repo_best:
        readme_best = _compose_readme(base, title_suffix="best")
        readme_best_path = os.path.join(base, "MODEL_README_BEST.md")
        with open(readme_best_path, "w") as f:
            f.write(readme_best)
        extra_files_best = [(readme_best_path, "README.md")]
        if os.path.exists(cm_png):
            extra_files_best.append((cm_png, "confusion_matrix.png"))
        repo_best_id = f"{args.repo_namespace}/{repo_best}"
        print(f"[push] Pushing best model: {best_dir} → {repo_best_id}")
        _push_dir(
            api,
            best_dir,
            repo_best_id,
            private=args.private,
            extra_files=extra_files_best,
            allow_patterns=allow_main,  # same keep-list is fine for best
            ignore_patterns=["**/*.pt", "**/events.*", "**/trainer_state.json", "**/training_args.bin"],
        )

    print("[push] Done.")


if __name__ == "__main__":
    main()
